{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d572d7a",
   "metadata": {},
   "source": [
    "# STATISTICAL LEARNING PROJECT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74063e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizzazione\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "\n",
    "# Modelli statistici\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Libreria ISLP (Statistical Learning)\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS ,summarize, poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carico il dataset e stampo l'head\n",
    "df = pd.read_csv(\"f1_pitstops_2018_2024.csv\", encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d505944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Colonne:\\n\\n\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Informazioni:\\n\\n\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistiche descrittive:\\n\\n\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cad6fd",
   "metadata": {},
   "source": [
    "## Check if the data contains any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb15cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controllo i dati nulli\n",
    "columnsWithNulls=df.isnull().sum().sort_values(ascending=False)\n",
    "columnsWithNulls=columnsWithNulls[columnsWithNulls>0]\n",
    "print(columnsWithNulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controllo in percentuale quanti dati mancano cosÃ¬ da capire come trattarli, pongo una soglia di eliminazione del regressore nel caso di +30% di dati mancanti\n",
    "missing_pct = df.isnull().mean() * 100\n",
    "missing_only = missing_pct[missing_pct > 0].sort_values(ascending=False)\n",
    "print(missing_only)\n",
    "sns.barplot(x=missing_only.values, y=missing_only.index)\n",
    "plt.title('Percentuale di valori nulli per colonna')\n",
    "plt.xlabel('% Missing')\n",
    "plt.ylabel('Colonna')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea73748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droppiamo le righe con i valori nulli e le colonne con piÃ¹ del 30% di dati nulli\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.drop(columns=missing_only[missing_only>30].index, inplace=True)\n",
    "df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808a2a1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79e23c",
   "metadata": {},
   "source": [
    "## Correlation HeatMap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aad7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona le colonne numeriche\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Controllo che ci siano almeno 4 variabili numeriche per evitare visualizzazioni poco utili\n",
    "if numeric_df.shape[1] >= 4:\n",
    "    # Calcola la matrice di correlazione\n",
    "    corr = numeric_df.corr()\n",
    "    \n",
    "    # Crea una maschera triangolare superiore per evitare ridondanza\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # Imposta la figura\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='coolwarm',\n",
    "        square=True,\n",
    "        linewidths=.5,\n",
    "        cbar_kws={\"shrink\": .75}\n",
    "    )\n",
    "    plt.title('Correlation Heatmap of Numeric Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric columns for a meaningful correlation heatmap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Seleziona solo le colonne numeriche e calcola la correlazione assoluta\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "corr = numeric_df.corr().abs()\n",
    "\n",
    "# 2. Prendi la metÃ  superiore (senza diagonale)\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "\n",
    "# 3. Trova tutte le colonne con correlazione > 0.99\n",
    "to_drop = upper.columns[upper.gt(0.99).any()].tolist()\n",
    "print(\"Tutte le colonne candidate al drop:\", to_drop)\n",
    "\n",
    "# 4. Rimuovi 'Driver Aggression Score' dalla lista, se presente\n",
    "to_drop = [col for col in to_drop if col != \"Driver Aggression Score\"]\n",
    "print(\"Colonne da droppare (escl. Driver Aggression Score):\", to_drop)\n",
    "\n",
    "# 5. Droppa le colonne selezionate (incluse quelle con > 0.99)\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# 6. Droppa anche AvgPitStopTime\n",
    "df.drop(columns=['AvgPitStopTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona le colonne numeriche\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Controllo che ci siano almeno 4 variabili numeriche per evitare visualizzazioni poco utili\n",
    "if numeric_df.shape[1] >= 4:\n",
    "    # Calcola la matrice di correlazione\n",
    "    corr = numeric_df.corr()\n",
    "    \n",
    "    # Crea una maschera triangolare superiore per evitare ridondanza\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # Imposta la figura\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='coolwarm',\n",
    "        square=True,\n",
    "        linewidths=.5,\n",
    "        cbar_kws={\"shrink\": .75}\n",
    "    )\n",
    "    plt.title('Correlation Heatmap of Numeric Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric columns for a meaningful correlation heatmap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15572266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona solo le variabili numeriche tranne 'Driver Aggression Score'\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "x_vars = [col for col in numeric_cols if col != 'Driver Aggression Score']\n",
    "\n",
    "# Controlla se ci sono abbastanza variabili da visualizzare\n",
    "n = len(x_vars)\n",
    "if n > 0:\n",
    "    # Imposta il layout della figura\n",
    "    fig, axes = plt.subplots(1, n, figsize=(5 * n, 5), sharey=True)\n",
    "\n",
    "    # Scatterplot di ogni variabile rispetto al Driver Aggression Score\n",
    "    for i, var in enumerate(x_vars):\n",
    "        sns.scatterplot(data=df, x=var, y='Driver Aggression Score', ax=axes[i])\n",
    "        axes[i].set_title(f'{var} vs Aggression')\n",
    "        axes[i].set_xlabel(var)\n",
    "\n",
    "    axes[0].set_ylabel('Driver Aggression Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Nessuna variabile numerica disponibile per il confronto con Driver Aggression Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4414859a",
   "metadata": {},
   "source": [
    "## TEST MODELLO LINEARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica che la colonna 'TotalPitStops' sia presente nel dataframe\n",
    "if 'TotalPitStops' in df.columns:\n",
    "    # Creazione del dataframe X con intercetta e la variabile indipendente 'TotalPitStops'\n",
    "    X = pd.DataFrame({\n",
    "        'intercept': np.ones(df.shape[0]),  # Colonna di 1 per l'intercetta\n",
    "        'TotalPitStops': df['TotalPitStops'],  # Feature indipendente\n",
    "    })\n",
    "    # Visualizza i primi 4 record di X\n",
    "    print(X.head(4))\n",
    "else:\n",
    "    print(\"'TotalPitStops' non Ã¨ presente nel dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5af31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica che la variabile target 'Driver Aggression Score' sia presente nel dataframe\n",
    "if 'Driver Aggression Score' in df.columns:\n",
    "    y = df['Driver Aggression Score']  # La variabile target\n",
    "    # Verifica che il numero di osservazioni sia maggiore del numero di variabili\n",
    "    if X.shape[0] > X.shape[1]:\n",
    "        # Definiamo il modello OLS\n",
    "        model = sm.OLS(y, X)  # Funzione per adattare una regressione lineare semplice\n",
    "        results = model.fit()  # Adattiamo il modello\n",
    "\n",
    "        # Mostriamo un riassunto dei risultati\n",
    "        print(results.summary())\n",
    "    else:\n",
    "        print(\"Il numero di osservazioni Ã¨ troppo basso rispetto al numero di variabili per un modello affidabile.\")\n",
    "else:\n",
    "    print(\"'Driver Aggression Score' non Ã¨ presente nel dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(results) #produces a simple table of the parameter estimates, their standard errors, t-statistics and p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0535aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Seleziona le colonne numeriche (senza 'Driver Aggression Score')\n",
    "numeric_cols = ['Season', 'Round', 'Laps', 'Position', 'Air_Temp_C', 'Humidity_%', 'Wind_Speed_KMH']\n",
    "\n",
    "X_numeric = df[numeric_cols]\n",
    "\n",
    "# 2. Normalizza le variabili numeriche usando StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# 3. Aggiungi la colonna dell'intercetta (bias)\n",
    "X_numeric_scaled = sm.add_constant(X_numeric_scaled)\n",
    "\n",
    "# 4. Definisci la variabile target\n",
    "y = df['Driver Aggression Score']\n",
    "\n",
    "# 5. Crea e adatta il modello\n",
    "model = sm.OLS(y, X_numeric_scaled)\n",
    "results = model.fit()\n",
    "\n",
    "# 6. Stampa un riepilogo\n",
    "print(results.summary())\n",
    "\n",
    "# 7. Verifica la collinearitÃ  (VIF - Variance Inflation Factor)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calcola il VIF per ogni variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = ['const'] + numeric_cols  # Aggiungi 'const' per l'intercetta\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric_scaled, i) for i in range(X_numeric_scaled.shape[1])]\n",
    "\n",
    "# Stampa il VIF per ogni variabile\n",
    "print(\"\\nVIF per ogni variabile:\")\n",
    "print(vif_data)\n",
    "\n",
    "# 8. Controllo della distribuzione della variabile target (istogramma)\n",
    "sns.histplot(y, kde=True)\n",
    "plt.title('Distribuzione di Driver Aggression Score')\n",
    "plt.show()\n",
    "\n",
    "# 9. Verifica dei residui: grafico dei residui\n",
    "residuals = results.resid\n",
    "sns.scatterplot(x=results.fittedvalues, y=residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Grafico dei residui')\n",
    "plt.xlabel('Valori Predetti')\n",
    "plt.ylabel('Residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080d320",
   "metadata": {},
   "source": [
    "# Interpretazione\n",
    "\n",
    "noto la distribuzione tutta schiacciata, provo a migliorala\n",
    "\n",
    "l'analisi dei residui mostra che il modello lineare Ã¨ troppo semplice per questo dataset\n",
    "\n",
    "I valori VIF ottenuti sono abbastanza bassi (intorno all'1) non ho correlazione tra le variabli e posso considerarle indipendenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed52a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transformed Aggression Score'] = np.log1p(df['Driver Aggression Score'])  # log(x + 1)\n",
    "sns.histplot(df['Transformed Aggression Score'], kde=True)\n",
    "plt.title('Distribuzione trasformata di Driver Aggression Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Seleziona le colonne numeriche (senza 'Transformed Aggression Score')\n",
    "numeric_cols = ['Season','Round','Laps','Position','Air_Temp_C','Humidity_%','Wind_Speed_KMH']\n",
    "\n",
    "X_numeric = df[numeric_cols]\n",
    "\n",
    "# 2. Aggiungi la colonna dell'intercetta (bias)\n",
    "X_numeric = sm.add_constant(X_numeric)\n",
    "\n",
    "# 3. Definisci la nuova variabile target trasformata\n",
    "y_transformed = df['Transformed Aggression Score']\n",
    "\n",
    "# 4. Crea e adatta il modello con la variabile target trasformata\n",
    "model = sm.OLS(y_transformed, X_numeric)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. Stampa un riepilogo\n",
    "print(results.summary())\n",
    "\n",
    "# 6. Verifica la collinearitÃ  (VIF - Variance Inflation Factor)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calcola il VIF per ogni variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X_numeric.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
    "\n",
    "# Stampa il VIF per ogni variabile\n",
    "print(\"\\nVIF per ogni variabile:\")\n",
    "print(vif_data)\n",
    "\n",
    "# 7. Controllo della distribuzione della variabile target trasformata (istogramma)\n",
    "sns.histplot(y_transformed, kde=True)\n",
    "plt.title('Distribuzione Trasformata di Driver Aggression Score')\n",
    "plt.show()\n",
    "\n",
    "# 8. Verifica dei residui: grafico dei residui\n",
    "residuals = results.resid\n",
    "sns.scatterplot(x=results.fittedvalues, y=residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Grafico dei residui')\n",
    "plt.xlabel('Valori Predetti')\n",
    "plt.ylabel('Residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498402fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raggruppo le ore per evitare overfitting\n",
    "df['Hour'] = pd.to_datetime(df['Time_of_race'].str.replace('Z', ''), format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Creo colonne combinate utili aumentando il rischio di overfit\n",
    "\n",
    "df['Constructor_Tire'] = df['Constructor'] + ' Ã— ' + df['Tire Compound']\n",
    "df['Location_Time'] = df['Location'] + ' Ã— ' + df['Hour'].astype(str)\n",
    "df['Temp_Humidity'] = df['Air_Temp_C'] * df['Humidity_%']\n",
    "\n",
    "# Controllo il numero di correlazioni che creo, se sono troppo poche sto solo mettendo rumore!\n",
    "print(df['Constructor_Tire'].nunique()) #105\n",
    "print(df['Location_Time'].nunique()) #30\n",
    "\n",
    "# Sono parecchie, cosÃ¬ facendo sto quindi aumentando la dimensionalitÃ  del modello, dovrÃ² filtrare solo per le correlazioni piÃ¹ frequenti e metto a \"Other\" le rimanenti\n",
    "\n",
    "common_constr_tire = df['Constructor_Tire'].value_counts()[df['Constructor_Tire'].value_counts() >= 10].index\n",
    "df['Constructor_Tire'] = df['Constructor_Tire'].where(df['Constructor_Tire'].isin(common_constr_tire), 'Other')\n",
    "\n",
    "common_loc_time = df['Location_Time'].value_counts()[df['Location_Time'].value_counts() >= 10].index\n",
    "df['Location_Time'] = df['Location_Time'].where(df['Location_Time'].isin(common_loc_time), 'Other')\n",
    "\n",
    "print(\"\\nNuovi valori:\")\n",
    "print(df['Constructor_Tire'].nunique()) #105\n",
    "print(df['Location_Time'].nunique()) #30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Seleziona le colonne numeriche (senza 'Transformed Aggression Score')\n",
    "numeric_cols = ['Season','Round','Laps','Position','Wind_Speed_KMH','Temp_Humidity']\n",
    "\n",
    "X_numeric = df[numeric_cols]\n",
    "\n",
    "# 2. Aggiungi la colonna dell'intercetta (bias)\n",
    "X_numeric = sm.add_constant(X_numeric)\n",
    "\n",
    "# 3. Definisci la nuova variabile target trasformata\n",
    "y_transformed = df['Transformed Aggression Score']\n",
    "\n",
    "# 4. Crea e adatta il modello con la variabile target trasformata\n",
    "model = sm.OLS(y_transformed, X_numeric)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. Stampa un riepilogo\n",
    "print(results.summary())\n",
    "\n",
    "# 6. Verifica la collinearitÃ  (VIF - Variance Inflation Factor)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calcola il VIF per ogni variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X_numeric.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
    "\n",
    "# Stampa il VIF per ogni variabile\n",
    "print(\"\\nVIF per ogni variabile:\")\n",
    "print(vif_data)\n",
    "\n",
    "# 7. Controllo della distribuzione della variabile target trasformata (istogramma)\n",
    "sns.histplot(y_transformed, kde=True)\n",
    "plt.title('Distribuzione Trasformata di Driver Aggression Score')\n",
    "plt.show()\n",
    "\n",
    "# 8. Verifica dei residui: grafico dei residui\n",
    "residuals = results.resid\n",
    "sns.scatterplot(x=results.fittedvalues, y=residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Grafico dei residui')\n",
    "plt.xlabel('Valori Predetti')\n",
    "plt.ylabel('Residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Seleziona le colonne numeriche (senza 'Transformed Aggression Score')\n",
    "numeric_cols = ['Season','Round','Laps','Position','Wind_Speed_KMH','Temp_Humidity']\n",
    "\n",
    "X_numeric = df[numeric_cols]\n",
    "\n",
    "# 2. Aggiungi la colonna dell'intercetta (bias)\n",
    "X_numeric = sm.add_constant(X_numeric)\n",
    "\n",
    "# 3. Definisci la nuova variabile target trasformata\n",
    "y = df['Driver Aggression Score']\n",
    "\n",
    "# 4. Crea e adatta il modello con la variabile target trasformata\n",
    "model = sm.OLS(y, X_numeric)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. Stampa un riepilogo\n",
    "print(results.summary())\n",
    "\n",
    "# 6. Verifica la collinearitÃ  (VIF - Variance Inflation Factor)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calcola il VIF per ogni variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X_numeric.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
    "\n",
    "# Stampa il VIF per ogni variabile\n",
    "print(\"\\nVIF per ogni variabile:\")\n",
    "print(vif_data)\n",
    "\n",
    "# 7. Controllo della distribuzione della variabile target trasformata (istogramma)\n",
    "sns.histplot(y, kde=True)\n",
    "plt.title('Distribuzione Trasformata di Driver Aggression Score')\n",
    "plt.show()\n",
    "\n",
    "# 8. Verifica dei residui: grafico dei residui\n",
    "residuals = results.resid\n",
    "sns.scatterplot(x=results.fittedvalues, y=residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Grafico dei residui')\n",
    "plt.xlabel('Valori Predetti')\n",
    "plt.ylabel('Residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7579bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 1. Normalizzazione delle variabili numeriche\n",
    "numeric_cols = ['Season','Round','Laps','Position','Air_Temp_C','Humidity_%','Wind_Speed_KMH','Temp_Humidity']\n",
    "\n",
    "# Separaro le variabili numeriche\n",
    "X_numeric = df[numeric_cols]\n",
    "\n",
    "# Normalizzo le variabili numeriche\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = pd.DataFrame(scaler.fit_transform(X_numeric), columns=X_numeric.columns)\n",
    "\n",
    "# 2. Verifico della multicollinearitÃ : Calcolare il VIF\n",
    "X_vif = sm.add_constant(X_numeric_scaled)\n",
    "\n",
    "# Calcolo del VIF per ogni variabile (Fattore di Inflazione della Varianza)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X_vif.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "\n",
    "# Filtro variabili con VIF > 10\n",
    "print(\"VIF per ogni variabile:\")\n",
    "print(vif_data)\n",
    "\n",
    "# Rimuovo le variabili con VIF > 10, se necessario\n",
    "high_vif = vif_data[vif_data[\"VIF\"] > 10]\n",
    "print(\"\\nVariabili con VIF alto (maggiore di 10):\")\n",
    "print(high_vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828d97c",
   "metadata": {},
   "source": [
    "Valuto l'opzione di utilizzare o solo air_temp_C e Humidity% o solo Temp_Humidity\n",
    "\n",
    "empiricamente decido anche di usare solo Location_Time invece che time e location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ebd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra tutte le righe nei print\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# === 1. Selezione delle colonne ===\n",
    "numeric_cols = ['Season', 'Round', 'Laps', 'Position', 'Wind_Speed_KMH', 'Air_Temp_C', 'Humidity_%']\n",
    "categorical_cols = ['Circuit', 'Constructor', 'Tire Compound', 'Constructor_Tire','Location_Time']\n",
    "\n",
    "# === 2. Separazione delle variabili numeriche e scaling ===\n",
    "X_numeric = df[numeric_cols]\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = pd.DataFrame(scaler.fit_transform(X_numeric), columns=X_numeric.columns)\n",
    "\n",
    "# === 3. Codifica delle variabili categoriche ===\n",
    "X_categorical = pd.get_dummies(df[categorical_cols], drop_first=True)\n",
    "X_categorical = X_categorical.astype(int)  # Assicura che siano int (0 o 1)\n",
    "\n",
    "# === 4. Costruzione del dataset finale X ===\n",
    "X = pd.concat([X_numeric_scaled, X_categorical], axis=1)\n",
    "X = X.apply(pd.to_numeric, errors='coerce')  # Forza tutto a numerico\n",
    "X = sm.add_constant(X)  # Aggiunge l'intercetta\n",
    "\n",
    "# === 5. Variabile target (y) ===\n",
    "y = pd.to_numeric(df['Driver Aggression Score'], errors='coerce')\n",
    "\n",
    "# === 6. Rimozione righe con NaN in X o y ===\n",
    "X_y = pd.concat([X, y], axis=1)  # unisci temporaneamente per pulire insieme\n",
    "X_y_clean = X_y.dropna()         # rimuovi tutte le righe con almeno un NaN\n",
    "\n",
    "X_clean = X_y_clean.drop(columns='Driver Aggression Score')\n",
    "y_clean = X_y_clean['Driver Aggression Score']\n",
    "\n",
    "# === 7. Regressione OLS con dati puliti ===\n",
    "model = sm.OLS(y_clean, X_clean)\n",
    "results = model.fit()\n",
    "\n",
    "# 5. Stampa un riepilogo\n",
    "print(results.summary())\n",
    "\n",
    "# === 9. Analisi delle variabili significative ===\n",
    "significant_vars = results.pvalues[results.pvalues < 0.05]\n",
    "print(\"\\nVariabili significative (p-value < 0.05):\")\n",
    "print(significant_vars)\n",
    "\n",
    "insignificant_vars = results.pvalues[results.pvalues >= 0.05]\n",
    "print(\"\\nVariabili insignificanti (p-value >= 0.05):\")\n",
    "print(insignificant_vars)\n",
    "\n",
    "# 7. Controllo della distribuzione della variabile target trasformata (istogramma)\n",
    "sns.histplot(y, kde=True)\n",
    "plt.title('Distribuzione Trasformata di Driver Aggression Score')\n",
    "plt.show()\n",
    "\n",
    "# 8. Verifica dei residui: grafico dei residui\n",
    "residuals = results.resid\n",
    "sns.scatterplot(x=results.fittedvalues, y=residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Grafico dei residui')\n",
    "plt.xlabel('Valori Predetti')\n",
    "plt.ylabel('Residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab1dcc",
   "metadata": {},
   "source": [
    "ðŸ“Š Valutazione del Modello\n",
    "âœ… R-squared: 0.727\n",
    "Significa che il 72.7% della varianza nell'aggressivitÃ  dei piloti Ã¨ spiegata dal tuo modello.\n",
    "\n",
    "In ambito sociale/comportamentale (come qui), un RÂ² sopra 0.7 Ã¨ giÃ  ottimo, considerando la complessitÃ  dellâ€™essere umano.\n",
    "\n",
    "âœ… Adjusted R-squared: 0.713\n",
    "Tiene conto del numero di variabili: hai 123 predittori (!).\n",
    "\n",
    "Il fatto che lâ€™Adjusted RÂ² non cali troppo rispetto a RÂ² indica che molte variabili contribuiscono realmente, oppure che il rumore non Ã¨ esagerato.\n",
    "\n",
    "âœ… F-statistic: 50.29, p-value: 0.00\n",
    "Questo test verifica se almeno una variabile ha effetto significativo sulla variabile target.\n",
    "\n",
    "Il p-value â‰ˆ 0 ti dice che il modello Ã¨ globalmente significativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa14fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 15. Rimuovo le variabili insignificanti dal DataFrame X\n",
    "insignificant_cols = insignificant_vars.index\n",
    "X_reduced = X.drop(columns=insignificant_cols)\n",
    "\n",
    "# 16. Pulisco i dati da NaN o infiniti\n",
    "X_reduced = X_reduced.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Allineo y alle righe rimaste in X_reduced\n",
    "y_aligned = y.loc[X_reduced.index]\n",
    "\n",
    "# 17. Riprovo a fare la regressione con il nuovo set di variabili\n",
    "model_reduced = sm.OLS(y_aligned, X_reduced)\n",
    "results_reduced = model_reduced.fit()\n",
    "\n",
    "# 18. Stampo un riepilogo dei risultati del nuovo modello\n",
    "print(results_reduced.summary())\n",
    "\n",
    "# 19. Calcolo e stampo R-squared e Adjusted R-squared per il nuovo modello\n",
    "r_squared_reduced = results_reduced.rsquared\n",
    "adjusted_r_squared_reduced = results_reduced.rsquared_adj\n",
    "\n",
    "print(f'R-squared (modello ridotto): {r_squared_reduced:.4f}')\n",
    "print(f'Adjusted R-squared (modello ridotto): {adjusted_r_squared_reduced:.4f}')\n",
    "\n",
    "\n",
    "# 8. Verifica dei residui: grafico dei residui\n",
    "residuals = results.resid\n",
    "sns.scatterplot(x=results.fittedvalues, y=residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Grafico dei residui')\n",
    "plt.xlabel('Valori Predetti')\n",
    "plt.ylabel('Residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93487680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residui del modello\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "residuals = results.resid\n",
    "\n",
    "# Istogramma + distribuzione normale\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribuzione dei residui')\n",
    "plt.xlabel('Residuo')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.show()\n",
    "\n",
    "# QQ Plot\n",
    "plt.figure(figsize=(6,6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('QQ Plot dei residui')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc692096",
   "metadata": {},
   "source": [
    "# Autocorrelazione dei residui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108143cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw = durbin_watson(residuals)\n",
    "print(f'Durbin-Watson statistic: {dw:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_vals = results.fittedvalues\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(x=fitted_vals, y=residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Valori Predetti')\n",
    "plt.ylabel('Residui')\n",
    "plt.title('Residui vs Valori Predetti')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
