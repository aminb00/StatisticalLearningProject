{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38434b4b",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942b4f6",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizzazione\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "\n",
    "# Modelli statistici\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Libreria ISLP (Statistical Learning)\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS ,summarize, poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3984303b",
   "metadata": {},
   "source": [
    "We will use the Aircraft Price dataset, from Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5b13e",
   "metadata": {},
   "source": [
    "### Dataset load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carico il dataset e stampo l'head\n",
    "data = pd.read_csv(\"Data/aircraft_price.csv\", encoding='utf-8')\n",
    "target = 'price'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e49012",
   "metadata": {},
   "source": [
    "### data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142823e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e31d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controllo i dati nulli\n",
    "columnsWithNulls=data.isnull().sum().sort_values(ascending=False)\n",
    "columnsWithNulls=columnsWithNulls[columnsWithNulls>0]\n",
    "print(columnsWithNulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controllo in percentuale quanti dati mancano cos√¨ da capire come trattarli, pongo una soglia di eliminazione del regressore nel caso di +30% di dati mancanti\n",
    "missing_pct = data.isnull().mean() * 100\n",
    "missing_only = missing_pct[missing_pct > 0].sort_values(ascending=False)\n",
    "print(missing_only )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop dati nulli\n",
    "data.dropna(axis=0, inplace=True)\n",
    "missing_pct = data.isnull().sum()\n",
    "print(\"Number of null data: \\n\")\n",
    "print(missing_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "# Handle missing or infinite values in the data\n",
    "numeric_data_cleaned = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "numeric_data_with_const = sm.add_constant(numeric_data_cleaned)\n",
    "\n",
    "# Calcola il VIF per ciascuna variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Regressor\"] = numeric_data_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data_with_const.values, i) for i in range(numeric_data_with_const.shape[1])]\n",
    "\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280a472",
   "metadata": {},
   "source": [
    "### Skewness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b9cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of all numeric variables\n",
    "numeric_cols = data.select_dtypes(include=['number']).columns\n",
    "n = len(numeric_cols)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n",
    "for ax, col in zip(axes.flatten(), numeric_cols):\n",
    "    sns.histplot(data[col], kde=True, ax=ax)\n",
    "    ax.set_title(col)\n",
    "\n",
    "# remove any unused subplots\n",
    "for ax in axes.flatten()[n:]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22439307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcooliamo la skewness\n",
    "skewness = data[numeric_cols].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "print(\"Skewness of numeric variables:\")\n",
    "print(skewness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colonne da log-trasformare (skewness > 1)\n",
    "skewed_feats = [\n",
    "    'fuel_tank', 'engine_power', 'landing_distance', 'empty_weight',\n",
    "    'all_eng_roc', 'range', 'wing_span', 'length',\n",
    "    'out_eng_roc', 'max_speed', 'cruise_speed', 'takeoff_distance'\n",
    "]\n",
    "\n",
    "# copia del dataset e applicazione del log(1+x)\n",
    "logData = data.copy()\n",
    "for col in skewed_feats:\n",
    "    logData[col] = np.log1p(logData[col])\n",
    "\n",
    "# log-trasformartion anche del target:\n",
    "logData['price'] = np.log1p(logData['price'])\n",
    "\n",
    "# logData √® ora il tuo dataset con le variabili selezionate log-trasformate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a277db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifichiamo la skewness\n",
    "# Plot distributions of all numeric variables\n",
    "numeric_cols = logData.select_dtypes(include=['number']).columns\n",
    "n = len(numeric_cols)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n",
    "for ax, col in zip(axes.flatten(), numeric_cols):\n",
    "    sns.histplot(logData[col], kde=True, ax=ax)\n",
    "    ax.set_title(col)\n",
    "\n",
    "# remove any unused subplots\n",
    "for ax in axes.flatten()[n:]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ad534",
   "metadata": {},
   "source": [
    "## log transformation of target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## faccio log del target e confronto con target originale\n",
    "target = 'price'\n",
    "log_target = np.log(data[target])\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[target], bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribuzione originale del target')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(log_target, bins=30, color='green', alpha=0.7)\n",
    "plt.title('Distribuzione log del target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8518c0",
   "metadata": {},
   "source": [
    "#\n",
    "- **Distribuzione originale** (istogramma blu): il prezzo √® fortemente asimmetrico a destra, con code lunghe fino a 5 M‚Ç¨ e una concentrazione massima attorno a 1‚Äì3 M‚Ç¨. Questo livello di skewness pu√≤ causare problemi di eteroschedasticit√† e di instabilit√† nella regressione OLS.  \n",
    "- **Distribuzione log** (istogramma verde): dopo aver fatto `log(price)`, i valori si raggruppano su una curva molto pi√π simile a una normale ‚Äî la coda lunga si riduce, e l‚Äôintervallo diventa circa 13.5‚Äì15.5 sul logaritmo naturale.  \n",
    "\n",
    "**Cosa ci dice?**  \n",
    "1. **Assunti di OLS**: il log‚Äêtransform aiuta a soddisfare meglio l‚Äôipotesi di normalit√† dei residui e di varianza costante.  \n",
    "2. **Linearit√† percentuale**: un modello lineare su \\(\\log(price)\\) interpreta i coefficienti come variazioni percentuali del prezzo, spesso pi√π sensate di variazioni assolute su una scala ampia.  \n",
    "3. **Robustezza**: riduci l‚Äôinfluenza degli outlier pi√π estremi, migliorando stabilit√† e predittivit√†.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3398eb",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef224543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona le colonne numeriche\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "if numeric_data.shape[1] >= 4:\n",
    "    # Calcola la matrice di correlazione\n",
    "    corr = numeric_data.corr()\n",
    "    \n",
    "    # Imposta la figura\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='inferno_r',\n",
    "        square=True,\n",
    "        linewidths=.5,\n",
    "        cbar_kws={\"shrink\": .75}\n",
    "    )\n",
    "    plt.title('Correlation Heatmap of Numeric Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric columns for a meaningful correlation heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona le colonne numeriche\n",
    "numeric_data = logData.select_dtypes(include=[np.number])\n",
    "if numeric_data.shape[1] >= 4:\n",
    "    # Calcola la matrice di correlazione\n",
    "    corr = numeric_data.corr()\n",
    "    \n",
    "    # Imposta la figura\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='inferno_r',\n",
    "        square=True,\n",
    "        linewidths=.5,\n",
    "        cbar_kws={\"shrink\": .75}\n",
    "    )\n",
    "    plt.title('Correlation Heatmap of Numeric Features (After Log Transformation)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric columns for a meaningful correlation heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d3dae",
   "metadata": {},
   "source": [
    "## VIF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fa6e5",
   "metadata": {},
   "source": [
    "### without log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Seleziona le colonne numeriche\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "# Handle missing or infinite values in the data\n",
    "numeric_data_cleaned = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "numeric_data_with_const = sm.add_constant(numeric_data_cleaned)\n",
    "# Calcola il VIF per ciascuna variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Regressor\"] = numeric_data_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data_with_const.values, i) for i in range(numeric_data_with_const.shape[1])]\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6959a3",
   "metadata": {},
   "source": [
    "### with log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Seleziona le colonne numeriche\n",
    "numeric_data = logData.select_dtypes(include=[np.number])\n",
    "# Handle missing or infinite values in the data\n",
    "numeric_data_cleaned = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "numeric_data_with_const = sm.add_constant(numeric_data_cleaned)\n",
    "# Calcola il VIF per ciascuna variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Regressor\"] = numeric_data_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data_with_const.values, i) for i in range(numeric_data_with_const.shape[1])]\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049cad7",
   "metadata": {},
   "source": [
    "**Commento sui VIF**  \n",
    "Dall‚Äôanalisi dei VIF emerge innanzitutto che alcune coppie di variabili sono fortemente collineari (in particolare **landing_distance** ed **empty_weight**, con VIF > 50 anche dopo la log-trasformazione). Questo fenomeno pu√≤ compromettere la stabilit√† numerica dei coefficienti OLS e rendere difficoltosa l‚Äôinterpretazione individuale degli effetti.  \n",
    "\n",
    "La log-trasformazione delle feature ha ridotto significativamente i VIF globali (ad es. landing_distance da ~172 a ~55, engine_power da ~24 a ~22, fuel_tank da ~27 a ~19), ma rimangono ancora variabili con VIF superiori a 10 (cruise_speed, length, fuel_tank, empty_weight).  \n",
    "\n",
    "üîπ **Prossimi passi consigliati**  \n",
    "1. **Rimuovere** o **combinare** le variabili con VIF estremamente alti (landing_distance vs empty_weight).  \n",
    "2. Valutare la creazione di feature derivate (es. rapporto `power/weight`) per catturare l‚Äôinformazione condivisa e ridurre la collinearit√†.  \n",
    "3. Utilizzare Ridge o Lasso nel modello finale, che penalizzano automaticamente le variabili pi√π collineari e stabilizzano la stima.  \n",
    "\n",
    "Cos√¨ avremo un modello pi√π robusto e interpretabile, con coefficienti meno sensibili alle ridondanze tra le covariate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3b1b2",
   "metadata": {},
   "source": [
    "## Feature engineering for VIF reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22806",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Ora otteniamo **df** che √® il nuovo dataframe uguale a logData a meno delle variabili con VIF > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_THRESHOLD = 10.0\n",
    "\n",
    "# partiamo da una copia di logData\n",
    "data_pruned = logData.copy()\n",
    "\n",
    "# consideriamo solo le colonne numeriche\n",
    "numeric_data_cleaned = (\n",
    "    data_pruned\n",
    "    .select_dtypes(include=[np.number])\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "variables = numeric_data_cleaned.columns.tolist()\n",
    "dropped_cols = []\n",
    "\n",
    "def calculate_vif(df):\n",
    "    df_const = sm.add_constant(df)\n",
    "    vif = pd.DataFrame({\n",
    "        \"Regressor\": df_const.columns,\n",
    "        \"VIF\": [\n",
    "            variance_inflation_factor(df_const.values, i)\n",
    "            for i in range(df_const.shape[1])\n",
    "        ]\n",
    "    })\n",
    "    return vif.sort_values(\"VIF\", ascending=False)\n",
    "\n",
    "while True:\n",
    "    vif_df = calculate_vif(numeric_data_cleaned[variables])\n",
    "    vif_no_const = vif_df[vif_df.Regressor != \"const\"]\n",
    "    max_vif = vif_no_const[\"VIF\"].max()\n",
    "    if max_vif <= VIF_THRESHOLD:\n",
    "        print(f\"Tutti i VIF sono sotto {VIF_THRESHOLD}\")\n",
    "        break\n",
    "    var_to_drop = vif_no_const.iloc[0][\"Regressor\"]\n",
    "    print(f\"Rimuovo {var_to_drop} (VIF={max_vif:.1f})\")\n",
    "    dropped_cols.append(var_to_drop)\n",
    "    variables.remove(var_to_drop)\n",
    "    numeric_data_cleaned.drop(columns=[var_to_drop], inplace=True)\n",
    "\n",
    "print(\"Colonne eliminate:\", dropped_cols)\n",
    "\n",
    "# otteniamo df senza toccare data/logData\n",
    "df = data_pruned.drop(columns=dropped_cols)\n",
    "print(\"Colonne finali in df:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c425e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF finale\n",
    "vif_final = calculate_vif(numeric_data_cleaned[variables])\n",
    "print(vif_final)\n",
    "\n",
    "#numeric_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745069de",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **df** √® il nuovo dataframe uguale a logData a meno delle variabili con VIF > 10.\n",
    "usiamo **df** d'ora in avanti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90bcd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap    \n",
    "\n",
    "numeric_data = df.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    numeric_data.corr(),\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    square=True,\n",
    "    linewidths=.5,\n",
    "    cbar_kws={\"shrink\": .75}\n",
    ")\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517359ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dadca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF\n",
    "numeric_data = df.select_dtypes(include=[np.number])\n",
    "# Handle missing or infinite values in the data\n",
    "numeric_data_cleaned = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "numeric_data_with_const = sm.add_constant(numeric_data_cleaned)\n",
    "# Calcola il VIF per ciascuna variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Regressor\"] = numeric_data_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data_with_const.values, i) for i in range(numeric_data_with_const.shape[1])]\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['roc_mean'] = (df['all_eng_roc'] + df['out_eng_roc']) / 2\n",
    "df['speed_margin'] = df['max_speed'] - df['stall_speed']\n",
    "df['power_per_distance'] = df['engine_power'] / df['takeoff_distance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "X_new = df[['roc_mean', 'speed_margin', 'power_per_distance', \n",
    "            'wing_span', 'range']]   # price esclusa\n",
    "X_new = add_constant(X_new)\n",
    "\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Regressor\"] = X_new.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_new.values, i) for i in range(X_new.shape[1])]\n",
    "\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e6460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nuovo df\n",
    "df = df[['price', 'roc_mean', 'speed_margin', 'power_per_distance', \n",
    "          'wing_span', 'range']]  # price inclusa\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3dcd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    df.corr(),\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    square=True,\n",
    "    linewidths=.5,\n",
    "    cbar_kws={\"shrink\": .75}\n",
    ")\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b872f87",
   "metadata": {},
   "source": [
    "### Heatmap con correlazioni molto alte\n",
    "# üí° Passo indietro: stesse feaatures ma non log-trasformate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d65c0",
   "metadata": {},
   "source": [
    "### Creazione di nuove features \n",
    "- **roc_mean**: velocit√† di salita media, calcolata come media tra `all_eng_roc` e `out_eng_roc`.  \n",
    "- **speed_margin**: margine di velocit√† operativo, ottenuto sottraendo la velocit√† di stallo (`stall_speed`) dalla velocit√† massima (`max_speed`).  \n",
    "- **power_per_distance**: potenza erogata per metro di decollo, dato dal rapporto tra `engine_power` su `takeoff_distance`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09627977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto con features non log‚Äêtrasformate\n",
    "df2 = data[['all_eng_roc', 'out_eng_roc', 'max_speed', 'stall_speed',\n",
    "            'engine_power', 'takeoff_distance', 'wing_span', 'range']].copy()\n",
    "\n",
    "# nuove feature\n",
    "df2['roc_mean'] = (df2['all_eng_roc'] + df2['out_eng_roc']) / 2\n",
    "df2['speed_margin'] = df2['max_speed'] - df2['stall_speed']\n",
    "df2['power_per_distance'] = df2['engine_power'] / df2['takeoff_distance']\n",
    "df2['price'] = data['price']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69a55b",
   "metadata": {},
   "source": [
    "## Rimozione delle features usate per la creazione di nuove features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selezione finale\n",
    "df2 = df2[['price', 'roc_mean', 'speed_margin', 'power_per_distance', 'wing_span', 'range']]\n",
    "\n",
    "print(df2.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    df2.corr(),\n",
    "    annot=True, fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    square=True,\n",
    "    linewidths=.5,\n",
    "    cbar_kws={\"shrink\": .75}\n",
    ")\n",
    "plt.title('Correlation Heatmap of Raw Selected Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF\n",
    "numeric_data = df2.select_dtypes(include=[np.number])\n",
    "# Handle missing or infinite values in the data\n",
    "numeric_data_cleaned = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "numeric_data_with_const = sm.add_constant(numeric_data_cleaned)\n",
    "# Calcola il VIF per ciascuna variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Regressor\"] = numeric_data_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data_with_const.values, i) for i in range(numeric_data_with_const.shape[1])]\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38513de",
   "metadata": {},
   "source": [
    "## üí° Usiamo **log-price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ora uso df2 ma con log price\n",
    "df2['price'] = np.log1p(df2['price'])\n",
    "# Seleziona le colonne numeriche\n",
    "numeric_data = df2.select_dtypes(include=[np.number])\n",
    "# Handle missing or infinite values in the data\n",
    "numeric_data_cleaned = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "numeric_data_with_const = sm.add_constant(numeric_data_cleaned)\n",
    "# Calcola il VIF per ciascuna variabile\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Regressor\"] = numeric_data_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(numeric_data_with_const.values, i) for i in range(numeric_data_with_const.shape[1])]\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap di df2\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    df2.corr(),\n",
    "    annot=True, fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    square=True,\n",
    "    linewidths=.5,\n",
    "    cbar_kws={\"shrink\": .75}\n",
    ")\n",
    "plt.title('Correlation Heatmap of Raw Selected Features (Log Transformed Price)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9792de",
   "metadata": {},
   "source": [
    "## Conclusione\n",
    "Dopo la skewness check log trasformando il dataset abbiamo ottenuto distribuzioni pi√π simmetriche e gaussiane. purtroppo dopo la VIF check abbiamo notato che alcune variabili sono altamente collineari.\n",
    "Nonostante la feature engineering la collinearit√† √® rimasta alta.\n",
    "### abbiamo deciso dunque di usare solo log price e il resto delle variabili senza log transformation.\n",
    "Otteniamo dunque VIF piu bassi e una heatmap piu chiara con meno collinearit√†."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1062759",
   "metadata": {},
   "source": [
    "### All data are cleaned from na values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b8279",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "data.to_csv(\"Data/aircraft_price_clean.csv\", index=False)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ab7cf",
   "metadata": {},
   "source": [
    "### logData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "logData.to_csv(\"Data/aircraft_price_cleaned_log.csv\", index=False)\n",
    "logData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62416bce",
   "metadata": {},
   "source": [
    "### After Feature Engineering and with log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "df.to_csv(\"Data/aircraft_price_best-logEngineered.csv\", index=False)\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff948f5",
   "metadata": {},
   "source": [
    "### After Feature Engineering and with out log transformation except for price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1249a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "df2.to_csv(\"Data/aircraft_price_Engineered.csv\", index=False)\n",
    "df2.columns "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StatLearning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
